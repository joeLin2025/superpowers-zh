---
name: skill-localization-and-polishing
description: 当需要创建、翻译或优化中文技能文档，且要求实现高信噪比、强约束力的专家级规范时使用。
---

# 技能本地化与极致打磨 (Skill Localization & Polishing)

## 概述

此技能是将普通文档升维为智能体“工程灵魂”的炼金术。它强制执行从“描述功能”到“塑造行为”的范式转移，通过**高信噪比表达 (High-SNR)**、**防御性博弈 (Defensive Game-play)** 以及 **外部基准对齐 (External Benchmarking)**，确保智能体在复杂生产环境下依然保持高度的确定性、专业纪律与行业领先性。

**核心原则：**
1.  **约束性表达 (Constraint-based)**：每一条规则都必须具备法律般的刚性。拒绝“建议”，拥抱“必须”与“严禁”。
2.  **认知完备性 (Cognitive Grounding)**：动作必须匹配原理。智能体只有理解了“为什么”，才能在边缘情况（Edge Cases）下做出正确的架构决策。
3.  **开放性进化 (Open Evolution)**：拒绝闭门造车。必须通过搜索与调研，将外部世界的最佳实践（SOTA）注入技能文档。

## 何时使用

- 翻译或优化现有的英文技能，使其符合中文语境下的工程习惯时。
- 智能体出现“执行偏差”（如：频繁漏写测试、方案过于简陋）需通过更新技能来修正行为时。
- 需要创建一个全新的专家角色，且希望该角色具备行业顶尖水准时。
- **批量任务场景**：用户要求检查、优化或创建多个技能文件时。

## 核心法则

### 1. 必须执行外部知识注入 (Mandatory Knowledge Injection)
在定义技能规则之前，**严禁**仅凭臆想创作。必须引入外部的高维标准：
- **动作**：调用 `google_web_search`。
- **对象**：搜索 "System Prompt for [Role]", "[Topic] best practices", "LLM prompt engineering [Field]" 等关键词。
- **目的**：寻找行业内现存的最佳指令集、思维框架或反模式（Anti-patterns），并将其转化为技能中的“铁律”。
- **原理**：智能体的上限取决于 Prompt 的质量。通过联网检索，站在巨人的肩膀上构建技能。

### 2. 必须执行架构级发散 (Mandatory Architecture Brainstorming)
对于复杂、模糊或全新的技能请求，**严禁**直接进入编写模式：
- **触发条件**：当技能涉及复杂的多步骤逻辑，或用户需求仅为一句话（如“帮我写个架构师技能”）时。
- **动作**：必须先激活 `brainstorming` 技能。
- **产出**：在 `brainstorming` 会话中产出技能的 **[角色画像]**、**[核心工作流]** 和 **[负面约束]**，经用户确认后，方可回到本技能进行文档撰写。

### 3. 必须执行意图锚定 (Intent Anchoring)
在下笔前，**必须**进行显式的长考，明确三个核心维度：
- **痛点对冲**：这个技能是为了防止哪种最常见的“智能体偷懒”或“逻辑幻觉”？
- **能力边界**：该技能在何处失效？它与哪个上位技能（如 `using-superpowers`）或下位技能（如 `TDD`）存在交接？
- **语态选择**：必须采用**指令式 (Imperative)** 语气。

### 4. 必须执行双重对抗博弈 (Dual-Agent Play)
在定稿前，**必须**在后台模拟以下两轮攻击：
- **第一轮：傻瓜/机械攻击 (The Machine Test)**
    - *攻击*：如果我不提供这个 Context，一个没有常识的程序会如何误解这条指令？
    - *修正*：补全逻辑链条，消除歧义。
- **第二轮：狡猾/律师攻击 (The Lawyer Test)**
    - *攻击*：作为一个想早点下班的 Agent，我能如何钻这条规则的漏洞来减少工作量？
    - *修正*：封堵语义漏洞，将“可选”升级为“强制”。

### 5. 必须实施“高密度表达” (High-Density Encoding)
- **术语精准化**：使用行业标准术语（如：原子化、幂等性、解耦、回归测试）替代冗长的白话。
- **原理植入**：在规则后紧跟【原理：...】，为指令注入决策权重。
- **铁律**：严禁为了字数简洁而牺牲逻辑的闭环。

### 6. 必须遵循“批量原子化”执行流 (Batch Serialization)
若涉及多个技能的优化：
- **必须**先激活 `writing-plans`。
- **强制串行**：每个回复周期（Round）只能处理 **1 个** 技能。
- **原因**：大模型的“注意力弥散”会导致多任务下的质量坍塌。逐个击破是维持专家级水准的唯一路径。

## 借口粉碎机 (Excuse Smasher)

| 借口 | 事实反击 |
|------|----------|
| “我不需要搜，我自己就会写” | 你的“会写”只是训练数据的平均水平。联网搜索能让你获取原本不存在于权重中的最新 SOTA 知识。 |
| “这个技能很简单，不需要脑暴” | 简单的技能往往最难写好，因为容易流于形式。`brainstorming` 能帮你挖掘出深层约束。 |
| “删掉所有解释会更省 Token” | 没有 Context 的指令会导致智能体在复杂场景下失去判断力，最终导致更多 Token 的调试浪费。 |
| “我写得很直白，傻子都能懂” | 永远不要低估 LLM 在长上下文中产生幻觉的能力。只有严丝合缝的逻辑才能对抗熵增。 |

## 危险信号 (Red Flags)

- **闭门造车**：在创建新技能时，没有使用 `google_web_search` 寻找外部参考。
- **跳过设计**：面对复杂需求，未激活 `brainstorming` 直接输出 Markdown 文件。
- **建议性词汇**：出现了“建议”、“可以”、“考虑”、“通常”等弱约束词。
- **逻辑真空**：只有 Action，没有 Why。
- **批量漂移**：在没有计划文件的情况下，试图在一个回复中修改 2 个以上技能。
